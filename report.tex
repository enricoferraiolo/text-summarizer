\documentclass[a4paper, 12pt]{article}

% Language setting
\usepackage[italian]{babel}

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{booktabs}

\title{\textbf{RELAZIONE: \\ Text-Summarizer}}
\author{Enrico Ferraiolo 0001191698}
\date{}

\begin{document}

\maketitle

\begin{center}
    \textbf{Laurea Magistrale in Informatica}\\
    \vspace{0.3cm}
    Corso: Natural Language Processing \\
    a.a. 2024-2025
    \vspace{2cm}
\end{center}

\newpage

\tableofcontents
\newpage

\section{Introduzione}
Questo progetto vuole implementare un modello di text summarization (riassunto dei testi) utilizzando un'architettura Sequence-to-Sequence (Seq2Seq) basata su reti LSTM (Long Short-Term Memory).\\
L'obiettivo principale è generare riassunti concisi e significativi a partire da recensioni di prodotti più lunghe, mantenendo il significato del testo originale.

\section{Dataset}
Per questo progetto è stato utilizzato il dataset \href{https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews}{SNAP Amazon Fine Food Reviews}, che contiene recensioni di prodotti alimentari di Amazon.\\
In particolare, il dataset contiene, per ogni riga, una recensione completa e il rispettivo riassunto.\\
Del dataset originale, composto da circa 500.000 righe, è stato selezionato un sottoinsieme di 10.000 righe per l'analisi e l'allenamento del modello.

\section{Preprocessing dei Dati}
Il preprocessing dei dati è una fase critica per garantire la qualità e l'efficacia del modello di summarization, infatti è fondamentale pulire e filtrare i dati in modo accurato.\\
Sul dataset, infatti, sono stati eseguiti diversi passaggi di pulizia e filtraggio dei dati per garantire qualità e coerenza al modello durante l'addestramento.\\
Vediamo di seguito gli step effettutati durante questa fase:
\subsection{Pulizia del Testo}
Sono stati applicati i seguenti step di preprocessing:

\begin{enumerate}
    \item \textbf{Conversione del testo in minuscolo}
    \begin{itemize}
        \item Questa conversione garantisce l'uniformità del testo, evitando che la stessa parola venga considerata diversa solo per la presenza di maiuscole.\\Ad esempio, "Home", "HOME" e "home" vengono trattate come la stessa parola, riducendo la dimensionalità del vocabolario e migliorando l'efficienza dell'addestramento.
    \end{itemize}

    \item \textbf{Rimozione dei tag HTML}
    \begin{itemize}
        \item Le recensioni potrebbero contenere tag HTML residui dal formato web originale. 
        Questi elementi non contribuiscono al significato semantico del testo e potrebbero interferire con l'apprendimento del modello, pertanto vengono rimossi.
    \end{itemize}

    \item \textbf{Espansione delle contrazioni}
    \begin{itemize}
        \item Le contrazioni nella lingua inglese (come "don't", "I'm", "we're") vengono espanse nelle loro forme complete ("do not", "I am", "we are").\\
        Questo processo vuole standardizzare e garantire coerenza in tutto il testo e aiuta il modello a catturare meglio le relazioni semantiche, eliminando variazioni non necessarie della stessa espressione.
    \end{itemize}

    \item \textbf{Rimozione degli apostrofi possessivi ('s)}
    \begin{itemize}
        \item La forma possessiva in inglese non altera sostanzialmente il significato della frase ai fini del riassunto.\\ 
        La sua rimozione semplifica il testo e riduce ulteriormente la dimensione del vocabolario, permettendo al modello di concentrarsi sui concetti principali.
    \end{itemize}

    \item \textbf{Eliminazione del testo tra parentesi}
    \begin{itemize}
        \item Il testo tra parentesi spesso contiene informazioni supplementari che non sono generalmente essenziali per il riassunto.\\ 
        La loro rimozione aiuta a mantenere il focus sulle informazioni principali della recensione.
    \end{itemize}

    \item \textbf{Rimozione della punteggiatura e caratteri speciali}
    \begin{itemize}
        \item La punteggiatura e i caratteri speciali, pur essendo importanti per la leggibilità umana, possono introdurre rumore nell'addestramento del modello.\\
        La loro rimozione semplifica il testo mantenendo intatto il contenuto semantico essenziale per la generazione del riassunto.
    \end{itemize}

    \item \textbf{Eliminazione delle stopwords}
    \begin{itemize}
        \item Le stopwords sono parole molto comuni (come "the", "is", "at", "which") che appaiono frequentemente ma portano poco significato semantico.\\
        La loro rimozione riduce significativamente la dimensionalità del problema senza perdere informazioni cruciali per il riassunto, permettendo al modello di concentrarsi sulle parole più significative.
    \end{itemize}

    \item \textbf{Rimozione delle parole troppo corte}
    \begin{itemize}
        \item Le parole molto corte (solitamente di una o due lettere) spesso non contribuiscono al significato del testo.\\
        La loro rimozione aiuta a ridurre ulteriormente il rumore nei dati, mantenendo solo i termini più significativi per l'analisi.
    \end{itemize}
\end{enumerate}

\subsection{Filtraggio dei Dati}
Dopo l'analisi statistica del dataset, sono stati applicati i seguenti vincoli:
TODO: INSERISCI IMMAGINE(?)
\begin{itemize}
    \item Lunghezza massima delle recensioni: 30 parole
    \item Lunghezza massima dei riassunti: 8 parole
\end{itemize}

Questi limiti sono stati determinati attraverso un'analisi statistica della distribuzione delle lunghezze nel dataset.

\subsection{Tokenizzazione e Token Speciali}
Per preparare i dati per il modello:
\begin{itemize}
    \item Sono stati aggiunti token speciali:
        \begin{itemize}
            \item "sostok" come marcatore di inizio sequenza
            \item "eostok" come marcatore di fine sequenza
        \end{itemize}
    \item È stata effettuata la tokenizzazione separata per:
        \begin{itemize}
            \item Recensioni (testo di input)
            \item Riassunti (testo di output)
        \end{itemize}
\end{itemize}

\section{Architettura del Modello}
L'implementazione del modello è stata strutturata seguendo i principi della programmazione orientata agli oggetti, con una chiara separazione delle responsabilità.

\subsection{Classe Base Astratta}
La classe \texttt{BaseModel} fornisce l'interfaccia base per tutti i modelli di summarization:
\begin{itemize}
    \item Definisce i metodi astratti per la costruzione dell'encoder e del decoder
    \item Implementa funzionalità comuni come il salvataggio del modello e l'inferenza
    \item Gestisce la conversione tra sequenze e testo
\end{itemize}

\subsection{Implementazione Seq2SeqLSTM}
La classe \texttt{Seq2SeqLSTM} implementa l'architettura specifica:

\subsubsection{Encoder}
L'encoder è composto da:
\begin{itemize}
    \item Layer di embedding con dimensione 100
    \item Tre layer LSTM in cascata con:
        \begin{itemize}
            \item Dimensione latente di 300 unità
            \item Dropout del 40\% per regolarizzazione
            \item Return sequences e return state attivati
        \end{itemize}
\end{itemize}

\subsubsection{Decoder}
Il decoder include:
\begin{itemize}
    \item Layer di embedding dedicato
    \item Layer LSTM con:
        \begin{itemize}
            \item Stessa dimensione latente dell'encoder
            \item Dropout del 40\%
            \item Recurrent dropout del 20\%
        \end{itemize}
    \item Meccanismo di attention per focalizzarsi sulle parti rilevanti dell'input
    \item Dense layer con softmax per la generazione del vocabolario di output
\end{itemize}

\section{Training del Modello}
Il training è stato eseguito utilizzando:
\begin{itemize}
    \item Split del dataset in training e validation set
    \item Monitoraggio della loss e validation loss durante l'addestramento
    \item Early stopping per prevenire l'overfitting
\end{itemize}

\section{Metriche di Valutazione}
Per valutare le performance del modello sono state utilizzate diverse metriche:

\subsection{ROUGE (Recall-Oriented Understudy for Gisting Evaluation)}
Sono state calcolate tre varianti di ROUGE:
\begin{itemize}
    \item ROUGE-1: confronta unigrammi tra il riassunto generato e quello di riferimento
    \item ROUGE-2: considera bigrammi per catturare la fluidità del testo
    \item ROUGE-L: identifica la sottosequenza comune più lunga
\end{itemize}

\subsection{Word Error Rate (WER)}
Il WER misura:
\begin{itemize}
    \item Il numero di operazioni necessarie per trasformare il testo generato in quello di riferimento
    \item Include inserzioni, cancellazioni e sostituzioni di parole
\end{itemize}

\subsection{Cosine Similarity}
Questa metrica:
\begin{itemize}
    \item Valuta la similarità semantica tra i vettori dei testi
    \item Fornisce un valore tra -1 e 1, dove 1 indica massima similarità
\end{itemize}

\section{Conclusioni}
Il modello implementato dimostra la capacità di generare riassunti efficaci delle recensioni di prodotti. L'architettura Seq2Seq con attention e la struttura modulare del codice permettono:
\begin{itemize}
    \item Facile estensibilità per futuri miglioramenti
    \item Buone performance nella generazione di riassunti
    \item Robustezza grazie alle tecniche di regolarizzazione implementate
\end{itemize}

\end{document}